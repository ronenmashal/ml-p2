{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9564f9b",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment\n",
    "\n",
    "Submitted by:\n",
    "- Ronen Mashal\n",
    "- Nir Schwartz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c2131",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook describes the progress and results of building a deep learning model to categorize the FASHION-MNIST images.\n",
    "Throughout the project we've attempted to utilize the tools offered by W&B, so much of our effort was actually directed towards managing the environment, in order to complete the project assignment while developing a work methodology involving the W&B tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aca16a",
   "metadata": {},
   "source": [
    "# The Basic Model\n",
    "\n",
    "We started with a very basic fully connected model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87146af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               157000    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 60)                6060      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,770\n",
      "Trainable params: 183,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def create_model(input_shape = (28, 28, 1), class_count = 10, dropout_rate = 0.2, \n",
    "                 activation = \"relu\", l1_size = 200, l2_size = 100, l3_size = 60, \n",
    "                 **kwd_args):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input(shape = input_shape),\n",
    "            keras.layers.Flatten(input_shape = input_shape),\n",
    "            keras.layers.Dense(l1_size, activation=activation),\n",
    "            keras.layers.Dropout(rate=dropout_rate),\n",
    "            keras.layers.Dense(l2_size, activation=activation),\n",
    "            keras.layers.Dropout(rate=dropout_rate),\n",
    "            keras.layers.Dense(l3_size, activation=activation),\n",
    "            keras.layers.Dropout(rate=dropout_rate),\n",
    "            keras.layers.Dense(class_count, activation='softmax')            \n",
    "        ]) \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e1ee7",
   "metadata": {},
   "source": [
    "The model offers several optimization points. We can change its behavior by:\n",
    "1. Changing the `dropout_rate` of the Dropout layers.\n",
    "2. Changing the size of each of the Dense layers (`l1_size`, `l2_size` and `l3_size`).\n",
    "3. Changing the Dense layers activation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bc446",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae71c",
   "metadata": {},
   "source": [
    "We loaded the fashion-mnist dataset, split it to train, validation and test sets, normalized the images (by dividing the pixel values by 255) and logged the datasets as a W&B project artifact, so it can be loaded as is later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "run = wandb.init(project=f\"ml-p2\", entity=\"ml-p2\", name=f\"jupyter-{timestamp}\"\n",
    "        notes = f\"Running FCNN model from jupyter @{timestamp}\", config = config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcfd99",
   "metadata": {},
   "source": [
    "# First Training Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3769b2",
   "metadata": {},
   "source": [
    "We first executed the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_set.images, train_set.labels, \n",
    "    validation_data = (validation_set.images, validation_set.labels), \n",
    "    epochs = config[\"epochs\"], \n",
    "    callbacks = [\n",
    "        WandbCallback()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_evaluation = model.evaluate(train_set.images, train_set.labels)\n",
    "test_evaluation = model.evaluate(test_set.images, test_set.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
